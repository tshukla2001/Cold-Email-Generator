{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8a70bde-7083-4d98-9e1c-a4e0497b56fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/f4/0c/75da081f5948e07f373a92087e4808739a3248d308f01c78c9bd4a51defa/pypdf-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.0 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/302.0 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 112.6/302.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 276.5/302.0 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.0/302.0 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -U langchain_groq\n",
    "#pip install -U langchain_community\n",
    "#pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6674f98-13d9-43a0-913e-8a455257e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The first man to walk on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon\\'s surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That\\'s one small step for man, one giant leap for mankind,\" as he became the first person to set foot on the moon.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 43, 'total_tokens': 118, 'completion_time': 0.272727273, 'prompt_time': 0.004928043, 'queue_time': 0.29434387700000003, 'total_time': 0.277655316}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_e669a124b2', 'finish_reason': 'stop', 'logprobs': None} id='run-24cdea29-13ff-4342-a2f6-398669f9f8f5-0' usage_metadata={'input_tokens': 43, 'output_tokens': 75, 'total_tokens': 118}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "cold_email_llm = ChatGroq(\n",
    "    model = \"llama-3.3-70b-versatile\",\n",
    "    temperature = 0.2,\n",
    "    max_retries = 2,\n",
    "    api_key = \"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\"\n",
    ")\n",
    "# res = cold_email_llm.invoke(\"First man to walk on moon was \")\n",
    "# print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0127e0e4-8957-419e-9007-179acd5f7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(web_path = \"https://www.google.com/about/careers/applications/jobs/results/109941891524371142-staff-data-scientist-product-google-play?location=India&q=%22Data%20Scientist%22\")\n",
    "page_data = loader.load().pop().page_content\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e104b264-c4ef-46c0-bf00-62d8272fe1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"role\": \"Staff Data Scientist, Product, Google Play\",\n",
      "  \"skills\": [\n",
      "    \"Statistics\",\n",
      "    \"Economics\",\n",
      "    \"Engineering\",\n",
      "    \"Mathematics\",\n",
      "    \"SQL\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Data analysis\",\n",
      "    \"Modeling\",\n",
      "    \"Experimentation\",\n",
      "    \"Causal inference\",\n",
      "    \"Data mining\",\n",
      "    \"Querying\",\n",
      "    \"Programming\"\n",
      "  ],\n",
      "  \"experience\": {\n",
      "    \"minimum\": {\n",
      "      \"years\": 7,\n",
      "      \"requirements\": [\n",
      "        \"Statistical data analysis\",\n",
      "        \"Modeling\",\n",
      "        \"Experimentation\",\n",
      "        \"Causal inference\",\n",
      "        \"Data mining\",\n",
      "        \"Querying\",\n",
      "        \"Managing analytical projects\"\n",
      "      ]\n",
      "    },\n",
      "    \"preferred\": {\n",
      "      \"years\": 5,\n",
      "      \"requirements\": [\n",
      "        \"Scripting or statistical analysis\",\n",
      "        \"Technical leadership role\",\n",
      "        \"People management experience\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"description\": \"Help serve Google's worldwide user base of more than a billion people. Data Scientists provide quantitative support, market understanding and a strategic perspective to our partners throughout the organization. As a data-loving member of the team, you serve as an analytics expert for your partners, using numbers to help them make better decisions.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### SCRAPED TEXT FROM GIVEN WEBSITE:\n",
    "    {data_of_page}\n",
    "    ### INSTRUCTION:\n",
    "    The scraped text is from the career's page of a website.\n",
    "    Your job is to analyze the data properly in detail and convert it into a JSON format which contains the following keys: `role`, `skills`, `experience`, `description`.\n",
    "    Only return a valid JSON format.\n",
    "    ### VALID JSON (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_for_extract = json_prompt | cold_email_llm\n",
    "res = chain_for_extract.invoke(input={'data_of_page': page_data})\n",
    "# print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "329f78c1-2b39-4a5f-9722-b3244dddac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Staff Data Scientist, Product, Google Play',\n",
       " 'skills': ['Statistics',\n",
       "  'Economics',\n",
       "  'Engineering',\n",
       "  'Mathematics',\n",
       "  'SQL',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Data analysis',\n",
       "  'Modeling',\n",
       "  'Experimentation',\n",
       "  'Causal inference',\n",
       "  'Data mining',\n",
       "  'Querying',\n",
       "  'Programming'],\n",
       " 'experience': {'minimum': {'years': 7,\n",
       "   'requirements': ['Statistical data analysis',\n",
       "    'Modeling',\n",
       "    'Experimentation',\n",
       "    'Causal inference',\n",
       "    'Data mining',\n",
       "    'Querying',\n",
       "    'Managing analytical projects']},\n",
       "  'preferred': {'years': 5,\n",
       "   'requirements': ['Scripting or statistical analysis',\n",
       "    'Technical leadership role',\n",
       "    'People management experience']}},\n",
       " 'description': \"Help serve Google's worldwide user base of more than a billion people. Data Scientists provide quantitative support, market understanding and a strategic perspective to our partners throughout the organization. As a data-loving member of the team, you serve as an analytics expert for your partners, using numbers to help them make better decisions.\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "parsed_data = json_parser.parse(res.content)\n",
    "parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72b51781-5ea2-4e5d-b9b8-86f3cc6fda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader_pdf = PyPDFLoader(file_path = \"./Tanay_Shukla_Data_Scientist.pdf\", mode = \"single\", pages_delimiter = \"\")\n",
    "resume_details = loader_pdf.load()[0].page_content\n",
    "# res = res.page_content\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b21d8d9-7411-40be-974b-907aed630dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"Name\": \"Tanay Shukla\",\n",
      "    \"Mobile No.\": [\"+1 720-335-1922\", \"+91 9166243848\"],\n",
      "    \"LinkedIn URL\": \"https://www.linkedin.com/in/tanay-shukla-569a03190\",\n",
      "    \"Summary\": \"A data science enthusiast currently pursuing a Master of Science (MS) in Data Science at the University of Colorado, Boulder backed by a strong foundation in Computer Science Engineering. With a proven track record of delivering impactful projects leveraging machine learning, deep learning and data analysis techniques. Technical Excellence complemented by strong leadership experience as an Academic Peer Advisor and Finance Head, underscoring collaborative spirit and initiative. Works well independently or in team-based environments to accomplish objectives.\",\n",
      "    \"Education\": [\n",
      "        {\n",
      "            \"Degree\": \"Master of Science in Data Science\",\n",
      "            \"University\": \"University of Colorado, Boulder, USA\",\n",
      "            \"Graduation Date\": \"May 2025\",\n",
      "            \"GPA\": \"3.93 / 4\"\n",
      "        },\n",
      "        {\n",
      "            \"Degree\": \"Bachelor of Technology in Information Technology\",\n",
      "            \"University\": \"Vellore Institute of Technology, India\",\n",
      "            \"Graduation Date\": \"2023\",\n",
      "            \"CGPA\": \"8.33 / 10\"\n",
      "        }\n",
      "    ],\n",
      "    \"Skills\": {\n",
      "        \"Programming Languages\": [\"Python\", \"SQL\", \"HTML\", \"CSS\", \"JavaScript\", \"React JS\", \"React Native\", \"R\"],\n",
      "        \"Tools & Libraries\": [\"NumPy\", \"pandas\", \"Matplotlib\", \"Git\", \"TensorFlow\", \"scikit-learn\", \"Beautiful Soup\", \"Apache Spark\", \"Hadoop\", \"LangGraph\", \"FAISS\"],\n",
      "        \"Data Visualization Tools & Libraries\": [\"Power BI\", \"Tableau\", \"seaborn\", \"Plotly\"],\n",
      "        \"Frameworks\": [\"Flask\", \"Selenium\", \"Dash\", \"Next.js\", \"FastAPI\", \"LangChain\"],\n",
      "        \"Databases\": [\"MySQL\", \"Oracle\", \"PostgreSQL\", \"MongoDB\", \"ChromaDB (Vector Database)\"],\n",
      "        \"Cloud Platforms\": [\"Amazon Web Services (AWS)\", \"Google Cloud Platform (GCP)\"],\n",
      "        \"Big Data & AI Tools\": [\"Apache Kafka\", \"Open Source LLMs (Llama, Mistral, Falcon, GPT4All)\", \"Retrieval-Augmented Generation (RAG)\"],\n",
      "        \"Data Engineering Skills\": [\"ETL (Extract, Transform, Load)\", \"Data Warehousing\", \"Data Architecture\", \"Data Profiling\", \"Data Mapping\"],\n",
      "        \"Core Concepts\": [\"Machine & Deep Learning\", \"Time Series Analysis\", \"Natural Language Processing (NLP)\", \"Generative AI\", \"Data Pipelines\"],\n",
      "        \"Soft Skills\": [\"Analytical Thinking\", \"Problem Solving & Decision Making\", \"Presentation & Communication Skills\", \"Creative Thinking\", \"Teamwork & Collaboration\", \"Time Management\", \"Adaptability\"]\n",
      "    },\n",
      "    \"Experience\": [],\n",
      "    \"Projects\": [\n",
      "        {\n",
      "            \"Project Name\": \"Finance RAG System for Multi-Hop Question Answering\",\n",
      "            \"Duration\": \"Dec 2024 - Feb 2025\",\n",
      "            \"Skills\": [\"LangChain\", \"RAG\", \"ChromaDB\", \"Open-source LLMs\", \"Next.js\", \"API integration\", \"Python\", \"Vector Search\", \"Full-stack Development\"],\n",
      "            \"Description\": \"Developed a finance-focused RAG system using LangChain for multi-hop question answering on stocks, crypto, and banking. Integrated free APIs to dynamically retrieve real-time stock and crypto data. Used ChromaDB for efficient vector search and open-source LLMs for accurate answer generation from PDFs and stored data. Designed and deployed a user-friendly interface with Next.js for seamless user interaction.\"\n",
      "        },\n",
      "        {\n",
      "            \"Project Name\": \"Automated Content Curation and Recommendation Platform\",\n",
      "            \"Duration\": \"Aug 2024 - Dec 2024\",\n",
      "            \"Skills\": [\"MongoDB\", \"Kafka\", \"Redis\", \"Kubernetes\", \"BERTTopic\", \"Prometheus\", \"Grafana\", \"RESTful APIs\", \"Google Cloud Platform (GCP)\", \"Python\"],\n",
      "            \"Description\": \"Developed a scalable system to aggregate process & deliver personalized content using MongoDB, Kafka, Redis & Kubernetes. Integrated APIs for real-time data collection and implemented BERTTopic for user-to-topic mapping. Optimized performance with Redis caching and monitored system health using Prometheus and Grafana. Achieved low-latency, personalized feed delivery for thousands of users and processed millions of content pieces daily.\"\n",
      "        },\n",
      "        {\n",
      "            \"Project Name\": \"Real Estate Price Prediction\",\n",
      "            \"Duration\": \"Dec 2023 - Feb 2024\",\n",
      "            \"Skills\": [\"Python\", \"NumPy\", \"Pandas\", \"Matplotlib\", \"scikit-learn\"],\n",
      "            \"Description\": \"Designed and implemented a real estate price prediction (predictive analytics) website that predicts home prices based on user inputs, utilizing the Bangalore home prices dataset from Kaggle. Developed a predictive model using Python’s scikit-learn and linear regression, incorporating essential data science practices such as data cleaning, outlier detection, feature engineering, dimensionality reduction, hyperparameter tuning. Created a Python Flask server to handle HTTP requests and serve predictions from the trained model. Built an interactive frontend using HTML, CSS, & JavaScript to allow users to input home features like square feet, no. of bedrooms effectively integrating all components into a cohesive web application.\"\n",
      "        }\n",
      "    ],\n",
      "    \"Certifications\": [\n",
      "        {\n",
      "            \"Certification Name\": \"Oracle Database SQL Certified Associate\",\n",
      "            \"Issuing Organization\": \"Oracle\",\n",
      "            \"Year\": \"2025\"\n",
      "        },\n",
      "        {\n",
      "            \"Certification Name\": \"PCEP - Certified Entry-Level Python Programmer\",\n",
      "            \"Issuing Organization\": \"Python Institute\",\n",
      "            \"Year\": \"2024\"\n",
      "        },\n",
      "        {\n",
      "            \"Certification Name\": \"Microsoft Certified: Azure AI Fundamentals\",\n",
      "            \"Issuing Organization\": \"Microsoft\",\n",
      "            \"Year\": \"2024\"\n",
      "        }\n",
      "    ],\n",
      "    \"Leadership roles\": [\n",
      "        {\n",
      "            \"Role\": \"Academic Peer Advisor (Computer Science)\",\n",
      "            \"Organization\": \"Student Academic Success Center, University of Colorado Boulder\",\n",
      "            \"Duration\": \"Jan - May 2024\"\n",
      "        },\n",
      "        {\n",
      "            \"Role\": \"Finance Head (IEEE - IAS Chapter)\",\n",
      "            \"Organization\": \"Vellore Institute of Technology Vellore, India\",\n",
      "            \"Duration\": \"Mar 2021 – Mar 2022\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "resume_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### RESUME CONTENT:\n",
    "    {resume_data}\n",
    "    ### INSTRUCTIONS:\n",
    "    This is the extracted data from a resume. Convert the data into a valid json format with the following keys: `Name`, `Mobile No.`, \n",
    "    `LinkedIn URL`, `Summary`, `Education`, `Skills`, Experience, `Projects`, `Certifications` and `Leadership roles`.\n",
    "    Convert into a valid json format\n",
    "    ### VALID JSON (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_for_resume = resume_prompt | cold_email_llm\n",
    "res = chain_for_resume.invoke(input = {'resume_data': resume_details})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e7707e05-1016-4963-8eda-80fb790341ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': 'Tanay Shukla',\n",
       " 'Mobile No.': ['+1 720-335-1922', '+91 9166243848'],\n",
       " 'LinkedIn URL': 'https://www.linkedin.com/in/tanay-shukla-569a03190',\n",
       " 'Summary': 'A data science enthusiast currently pursuing a Master of Science (MS) in Data Science at the University of Colorado, Boulder backed by a strong foundation in Computer Science Engineering. With a proven track record of delivering impactful projects leveraging machine learning, deep learning and data analysis techniques. Technical Excellence complemented by strong leadership experience as an Academic Peer Advisor and Finance Head, underscoring collaborative spirit and initiative. Works well independently or in team-based environments to accomplish objectives.',\n",
       " 'Education': [{'Degree': 'Master of Science in Data Science',\n",
       "   'University': 'University of Colorado, Boulder, USA',\n",
       "   'Graduation Date': 'May 2025',\n",
       "   'GPA': '3.93 / 4'},\n",
       "  {'Degree': 'Bachelor of Technology in Information Technology',\n",
       "   'University': 'Vellore Institute of Technology, India',\n",
       "   'Graduation Date': '2023',\n",
       "   'CGPA': '8.33 / 10'}],\n",
       " 'Skills': {'Programming Languages': ['Python',\n",
       "   'SQL',\n",
       "   'HTML',\n",
       "   'CSS',\n",
       "   'JavaScript',\n",
       "   'React JS',\n",
       "   'React Native',\n",
       "   'R'],\n",
       "  'Tools & Libraries': ['NumPy',\n",
       "   'pandas',\n",
       "   'Matplotlib',\n",
       "   'Git',\n",
       "   'TensorFlow',\n",
       "   'scikit-learn',\n",
       "   'Beautiful Soup',\n",
       "   'Apache Spark',\n",
       "   'Hadoop',\n",
       "   'LangGraph',\n",
       "   'FAISS'],\n",
       "  'Data Visualization Tools & Libraries': ['Power BI',\n",
       "   'Tableau',\n",
       "   'seaborn',\n",
       "   'Plotly'],\n",
       "  'Frameworks': ['Flask',\n",
       "   'Selenium',\n",
       "   'Dash',\n",
       "   'Next.js',\n",
       "   'FastAPI',\n",
       "   'LangChain'],\n",
       "  'Databases': ['MySQL',\n",
       "   'Oracle',\n",
       "   'PostgreSQL',\n",
       "   'MongoDB',\n",
       "   'ChromaDB (Vector Database)'],\n",
       "  'Cloud Platforms': ['Amazon Web Services (AWS)',\n",
       "   'Google Cloud Platform (GCP)'],\n",
       "  'Big Data & AI Tools': ['Apache Kafka',\n",
       "   'Open Source LLMs (Llama, Mistral, Falcon, GPT4All)',\n",
       "   'Retrieval-Augmented Generation (RAG)'],\n",
       "  'Data Engineering Skills': ['ETL (Extract, Transform, Load)',\n",
       "   'Data Warehousing',\n",
       "   'Data Architecture',\n",
       "   'Data Profiling',\n",
       "   'Data Mapping'],\n",
       "  'Core Concepts': ['Machine & Deep Learning',\n",
       "   'Time Series Analysis',\n",
       "   'Natural Language Processing (NLP)',\n",
       "   'Generative AI',\n",
       "   'Data Pipelines'],\n",
       "  'Soft Skills': ['Analytical Thinking',\n",
       "   'Problem Solving & Decision Making',\n",
       "   'Presentation & Communication Skills',\n",
       "   'Creative Thinking',\n",
       "   'Teamwork & Collaboration',\n",
       "   'Time Management',\n",
       "   'Adaptability']},\n",
       " 'Experience': [],\n",
       " 'Projects': [{'Project Name': 'Finance RAG System for Multi-Hop Question Answering',\n",
       "   'Duration': 'Dec 2024 - Feb 2025',\n",
       "   'Skills': ['LangChain',\n",
       "    'RAG',\n",
       "    'ChromaDB',\n",
       "    'Open-source LLMs',\n",
       "    'Next.js',\n",
       "    'API integration',\n",
       "    'Python',\n",
       "    'Vector Search',\n",
       "    'Full-stack Development'],\n",
       "   'Description': 'Developed a finance-focused RAG system using LangChain for multi-hop question answering on stocks, crypto, and banking. Integrated free APIs to dynamically retrieve real-time stock and crypto data. Used ChromaDB for efficient vector search and open-source LLMs for accurate answer generation from PDFs and stored data. Designed and deployed a user-friendly interface with Next.js for seamless user interaction.'},\n",
       "  {'Project Name': 'Automated Content Curation and Recommendation Platform',\n",
       "   'Duration': 'Aug 2024 - Dec 2024',\n",
       "   'Skills': ['MongoDB',\n",
       "    'Kafka',\n",
       "    'Redis',\n",
       "    'Kubernetes',\n",
       "    'BERTTopic',\n",
       "    'Prometheus',\n",
       "    'Grafana',\n",
       "    'RESTful APIs',\n",
       "    'Google Cloud Platform (GCP)',\n",
       "    'Python'],\n",
       "   'Description': 'Developed a scalable system to aggregate process & deliver personalized content using MongoDB, Kafka, Redis & Kubernetes. Integrated APIs for real-time data collection and implemented BERTTopic for user-to-topic mapping. Optimized performance with Redis caching and monitored system health using Prometheus and Grafana. Achieved low-latency, personalized feed delivery for thousands of users and processed millions of content pieces daily.'},\n",
       "  {'Project Name': 'Real Estate Price Prediction',\n",
       "   'Duration': 'Dec 2023 - Feb 2024',\n",
       "   'Skills': ['Python', 'NumPy', 'Pandas', 'Matplotlib', 'scikit-learn'],\n",
       "   'Description': 'Designed and implemented a real estate price prediction (predictive analytics) website that predicts home prices based on user inputs, utilizing the Bangalore home prices dataset from Kaggle. Developed a predictive model using Python’s scikit-learn and linear regression, incorporating essential data science practices such as data cleaning, outlier detection, feature engineering, dimensionality reduction, hyperparameter tuning. Created a Python Flask server to handle HTTP requests and serve predictions from the trained model. Built an interactive frontend using HTML, CSS, & JavaScript to allow users to input home features like square feet, no. of bedrooms effectively integrating all components into a cohesive web application.'}],\n",
       " 'Certifications': [{'Certification Name': 'Oracle Database SQL Certified Associate',\n",
       "   'Issuing Organization': 'Oracle',\n",
       "   'Year': '2025'},\n",
       "  {'Certification Name': 'PCEP - Certified Entry-Level Python Programmer',\n",
       "   'Issuing Organization': 'Python Institute',\n",
       "   'Year': '2024'},\n",
       "  {'Certification Name': 'Microsoft Certified: Azure AI Fundamentals',\n",
       "   'Issuing Organization': 'Microsoft',\n",
       "   'Year': '2024'}],\n",
       " 'Leadership roles': [{'Role': 'Academic Peer Advisor (Computer Science)',\n",
       "   'Organization': 'Student Academic Success Center, University of Colorado Boulder',\n",
       "   'Duration': 'Jan - May 2024'},\n",
       "  {'Role': 'Finance Head (IEEE - IAS Chapter)',\n",
       "   'Organization': 'Vellore Institute of Technology Vellore, India',\n",
       "   'Duration': 'Mar 2021 – Mar 2022'}]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_json = json_parser.parse(res.content)\n",
    "resume_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6905a7d4-7d7b-4ec8-a300-22cf66b7e99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
