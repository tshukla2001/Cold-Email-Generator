{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6674f98-13d9-43a0-913e-8a455257e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "cold_email_llm = ChatGroq(\n",
    "    model = \"llama-3.3-70b-versatile\",\n",
    "    temperature = 0.2,\n",
    "    max_retries = 2,\n",
    "    api_key = \"api_key"\n",
    ")\n",
    "# res = cold_email_llm.invoke(\"First man to walk on moon was \")\n",
    "# print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0127e0e4-8957-419e-9007-179acd5f7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(web_path = \"https://www.google.com/about/careers/applications/jobs/results/109941891524371142-staff-data-scientist-product-google-play?location=India&q=%22Data%20Scientist%22\")\n",
    "page_data = loader.load().pop().page_content\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e104b264-c4ef-46c0-bf00-62d8272fe1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### SCRAPED TEXT FROM GIVEN WEBSITE:\n",
    "    {data_of_page}\n",
    "    ### INSTRUCTION:\n",
    "    The scraped text is from the career's page of a website.\n",
    "    Your job is to analyze the data properly in detail and convert it into a JSON format which contains the following keys: `role`, `skills`, `experience`, `description`.\n",
    "    Only return a valid JSON format.\n",
    "    ### VALID JSON (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_for_extract = json_prompt | cold_email_llm\n",
    "json_job_page = chain_for_extract.invoke(input={'data_of_page': page_data})\n",
    "# print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "329f78c1-2b39-4a5f-9722-b3244dddac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Staff Data Scientist, Product, Google Play',\n",
       " 'skills': ['Statistics',\n",
       "  'Economics',\n",
       "  'Engineering',\n",
       "  'Mathematics',\n",
       "  'SQL',\n",
       "  'Python',\n",
       "  'R',\n",
       "  'Data analysis',\n",
       "  'Modeling',\n",
       "  'Experimentation',\n",
       "  'Causal inference',\n",
       "  'Data mining',\n",
       "  'Querying',\n",
       "  'Programming'],\n",
       " 'experience': {'minimum': {'years': 7,\n",
       "   'requirements': ['Statistical data analysis',\n",
       "    'Modeling',\n",
       "    'Experimentation',\n",
       "    'Causal inference',\n",
       "    'Data mining',\n",
       "    'Querying',\n",
       "    'Managing analytical projects']},\n",
       "  'preferred': {'years': 5,\n",
       "   'requirements': ['Scripting or statistical analysis',\n",
       "    'Technical leadership role',\n",
       "    'People management experience']}},\n",
       " 'description': \"Help serve Google's worldwide user base of more than a billion people. Data Scientists provide quantitative support, market understanding and a strategic perspective to our partners throughout the organization. As a data-loving member of the team, you serve as an analytics expert for your partners, using numbers to help them make better decisions.\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "parsed_job_data = json_parser.parse(json_job_page.content)\n",
    "parsed_job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72b51781-5ea2-4e5d-b9b8-86f3cc6fda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader_pdf = PyPDFLoader(file_path = \"./Tanay_Shukla_Data_Scientist.pdf\", mode = \"single\", pages_delimiter = \"\")\n",
    "resume_details = loader_pdf.load()[0].page_content\n",
    "# res = res.page_content\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b21d8d9-7411-40be-974b-907aed630dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### RESUME CONTENT:\n",
    "    {resume_data}\n",
    "    ### INSTRUCTIONS:\n",
    "    This is the extracted data from a resume. Convert the data into a valid json format with the following keys: `name`, `mobile no.`, \n",
    "    `linkedin URL`, `summary`, `education`, `skills`, experience, `projects`, `certifications` and `leadership roles`.\n",
    "    Convert into a valid json format\n",
    "    ### VALID JSON (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_for_resume = resume_prompt | cold_email_llm\n",
    "extracted_resume = chain_for_resume.invoke(input = {'resume_data': resume_details})\n",
    "# print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7707e05-1016-4963-8eda-80fb790341ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Tanay Shukla',\n",
       " 'mobile no.': ['+1 720-335-1922', '+91 9166243848'],\n",
       " 'linkedin URL': 'https://www.linkedin.com/in/tanay-shukla-569a03190',\n",
       " 'summary': 'A data science enthusiast currently pursuing a Master of Science (MS) in Data Science at the University of Colorado, Boulder backed by a strong foundation in Computer Science Engineering. With a proven track record of delivering impactful projects leveraging machine learning, deep learning and data analysis techniques. Technical Excellence complemented by strong leadership experience as an Academic Peer Advisor and Finance Head, underscoring collaborative spirit and initiative. Works well independently or in team-based environments to accomplish objectives.',\n",
       " 'education': [{'degree': 'Master of Science in Data Science',\n",
       "   'university': 'University of Colorado, Boulder, USA',\n",
       "   'graduation': 'May 2025',\n",
       "   'GPA': '3.93 / 4'},\n",
       "  {'degree': 'Bachelor of Technology in Information Technology',\n",
       "   'university': 'Vellore Institute of Technology, India',\n",
       "   'graduation': '2023',\n",
       "   'CGPA': '8.33 / 10'}],\n",
       " 'skills': {'programming languages': ['Python',\n",
       "   'SQL',\n",
       "   'HTML',\n",
       "   'CSS',\n",
       "   'JavaScript',\n",
       "   'React JS',\n",
       "   'React Native',\n",
       "   'R'],\n",
       "  'tools and libraries': ['NumPy',\n",
       "   'pandas',\n",
       "   'Matplotlib',\n",
       "   'Git',\n",
       "   'TensorFlow',\n",
       "   'scikit-learn',\n",
       "   'Beautiful Soup',\n",
       "   'Apache Spark',\n",
       "   'Hadoop',\n",
       "   'LangGraph',\n",
       "   'FAISS'],\n",
       "  'data visualization tools and libraries': ['Power BI',\n",
       "   'Tableau',\n",
       "   'seaborn',\n",
       "   'Plotly'],\n",
       "  'frameworks': ['Flask',\n",
       "   'Selenium',\n",
       "   'Dash',\n",
       "   'Next.js',\n",
       "   'FastAPI',\n",
       "   'LangChain'],\n",
       "  'databases': ['MySQL',\n",
       "   'Oracle',\n",
       "   'PostgreSQL',\n",
       "   'MongoDB',\n",
       "   'ChromaDB (Vector Database)'],\n",
       "  'cloud platforms': ['Amazon Web Services (AWS)',\n",
       "   'Google Cloud Platform (GCP)'],\n",
       "  'big data and AI tools': ['Apache Kafka',\n",
       "   'Open Source LLMs (Llama, Mistral, Falcon, GPT4All)',\n",
       "   'Retrieval-Augmented Generation (RAG)'],\n",
       "  'data engineering skills': ['ETL (Extract, Transform, Load)',\n",
       "   'Data Warehousing',\n",
       "   'Data Architecture',\n",
       "   'Data Profiling',\n",
       "   'Data Mapping'],\n",
       "  'core concepts': ['Machine & Deep Learning',\n",
       "   'Time Series Analysis',\n",
       "   'Natural Language Processing (NLP)',\n",
       "   'Generative AI',\n",
       "   'Data Pipelines'],\n",
       "  'soft skills': ['Analytical Thinking',\n",
       "   'Problem Solving & Decision Making',\n",
       "   'Presentation & Communication Skills',\n",
       "   'Creative Thinking',\n",
       "   'Teamwork & Collaboration',\n",
       "   'Time Management',\n",
       "   'Adaptability']},\n",
       " 'experience': [],\n",
       " 'projects': [{'name': 'Finance RAG System for Multi-Hop Question Answering',\n",
       "   'duration': 'Dec 2024 - Feb 2025',\n",
       "   'skills': ['LangChain',\n",
       "    'RAG',\n",
       "    'ChromaDB',\n",
       "    'Open-source LLMs',\n",
       "    'Next.js',\n",
       "    'API integration',\n",
       "    'Python',\n",
       "    'Vector Search',\n",
       "    'Full-stack Development'],\n",
       "   'description': 'Developed a finance-focused RAG system using LangChain for multi-hop question answering on stocks, crypto, and banking. Integrated free APIs to dynamically retrieve real-time stock and crypto data. Used ChromaDB for efficient vector search and open-source LLMs for accurate answer generation from PDFs and stored data. Designed and deployed a user-friendly interface with Next.js for seamless user interaction.'},\n",
       "  {'name': 'Automated Content Curation and Recommendation Platform',\n",
       "   'duration': 'Aug 2024 - Dec 2024',\n",
       "   'skills': ['MongoDB',\n",
       "    'Kafka',\n",
       "    'Redis',\n",
       "    'Kubernetes',\n",
       "    'BERTTopic',\n",
       "    'Prometheus',\n",
       "    'Grafana',\n",
       "    'RESTful APIs',\n",
       "    'Google Cloud Platform (GCP)',\n",
       "    'Python'],\n",
       "   'description': 'Developed a scalable system to aggregate process & deliver personalized content using MongoDB, Kafka, Redis & Kubernetes. Integrated APIs for real-time data collection and implemented BERTTopic for user-to-topic mapping. Optimized performance with Redis caching and monitored system health using Prometheus and Grafana. Achieved low-latency, personalized feed delivery for thousands of users and processed millions of content pieces daily.'},\n",
       "  {'name': 'Real Estate Price Prediction',\n",
       "   'duration': 'Dec 2023 - Feb 2024',\n",
       "   'skills': ['Python', 'NumPy', 'Pandas', 'Matplotlib', 'scikit-learn'],\n",
       "   'description': 'Designed and implemented a real estate price prediction (predictive analytics) website that predicts home prices based on user inputs, utilizing the Bangalore home prices dataset from Kaggle. Developed a predictive model using Python’s scikit-learn and linear regression, incorporating essential data science practices such as data cleaning, outlier detection, feature engineering, dimensionality reduction, hyperparameter tuning. Created a Python Flask server to handle HTTP requests and serve predictions from the trained model. Built an interactive frontend using HTML, CSS, & JavaScript to allow users to input home features like square feet, no. of bedrooms effectively integrating all components into a cohesive web application.'}],\n",
       " 'certifications': [{'name': 'Oracle Database SQL Certified Associate',\n",
       "   'issuer': 'Oracle',\n",
       "   'year': '2025'},\n",
       "  {'name': 'PCEP - Certified Entry-Level Python Programmer',\n",
       "   'issuer': 'Python Institute',\n",
       "   'year': '2024'},\n",
       "  {'name': 'Microsoft Certified: Azure AI Fundamentals',\n",
       "   'issuer': 'Microsoft',\n",
       "   'year': '2024'}],\n",
       " 'leadership roles': [{'role': 'Academic Peer Advisor (Computer Science)',\n",
       "   'organization': 'Student Academic Success Center, University of Colorado Boulder',\n",
       "   'duration': 'Jan - May 2024'},\n",
       "  {'role': 'Finance Head (IEEE - IAS Chapter)',\n",
       "   'organization': 'Vellore Institute of Technology Vellore, India',\n",
       "   'duration': 'Mar 2021 – Mar 2022'}]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_json = json_parser.parse(extracted_resume.content)\n",
    "resume_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6905a7d4-7d7b-4ec8-a300-22cf66b7e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Staff Data Scientist, Product, Google Play\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my strong interest in the Staff Data Scientist, Product, Google Play position at Google. As a data science enthusiast with a Master of Science in Data Science from the University of Colorado, Boulder, I am confident that my skills and passion for data analysis make me an ideal candidate for this role. With a strong foundation in computer science engineering and a proven track record of delivering impactful projects, I am excited about the opportunity to join the Google team and contribute to the company's mission.\n",
      "\n",
      "As a detail-oriented and analytical individual, I have developed a range of skills that I believe would be valuable in this position. My academic experience has provided me with a solid understanding of data science concepts, including machine learning, deep learning, and data analysis techniques. Although I don't have direct industry experience, I have worked on several projects that demonstrate my ability to apply theoretical concepts to real-world problems. Some of my notable projects include:\n",
      "* Finance RAG System for Multi-Hop Question Answering: Developed a finance-focused RAG system using LangChain for multi-hop question answering on stocks, crypto, and banking.\n",
      "* Automated Content Curation and Recommendation Platform: Developed a scalable system to aggregate, process, and deliver personalized content using MongoDB, Kafka, Redis, and Kubernetes.\n",
      "* Real Estate Price Prediction: Designed and implemented a real estate price prediction website that predicts home prices based on user inputs, utilizing the Bangalore home prices dataset from Kaggle.\n",
      "\n",
      "In addition to my projects, I have also obtained several certifications that demonstrate my expertise in data science and related fields. I am an Oracle Database SQL Certified Associate, a Certified Entry-Level Python Programmer, and a Microsoft Certified: Azure AI Fundamentals. These certifications have not only enhanced my technical skills but also given me a competitive edge in the industry. I have attached my resume to this email for further reference, which provides more details about my education, skills, and certifications.\n",
      "\n",
      "I am excited about the opportunity to discuss my application and how my skills and experience align with the requirements of the Staff Data Scientist, Product, Google Play position. Thank you for considering my application. I look forward to the opportunity to contribute to the Google team and learn from the best in the industry.\n",
      "\n",
      "Sincerely,\n",
      "Tanay Shukla\n",
      "https://www.linkedin.com/in/tanay-shukla-569a03190\n",
      "+1 720-335-1922, +91 9166243848\n"
     ]
    }
   ],
   "source": [
    "cold_email_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### JOB DETAILS IN JSON:\n",
    "    {job_details_json}\n",
    "    ### RESUME DEATILS IN JSON:\n",
    "    {resume_details_json}\n",
    "    ### INSTRUCTIONS:\n",
    "    The above two are json formats of a job detail from a career's page of a website and the resume details of a person respectively. Analyze both and\n",
    "    generate a mail with a subject and a salutation addressed to the hiring manager of the company. The mail should showcase the person's interest\n",
    "    (whose resume is attached) in the job highlighting the important details from their resume and not the ones mentioned in the job detail. Don't \n",
    "    mention anything about the person's `experience` if there is nothing in the resume and only talk about the person's experience if he/she has \n",
    "    some `experience` in the resume. If there is no `experience` in the resume then talk about academic experience through projects else talk about \n",
    "    the person's `experience` in the resume like what did they do in the company and what skills were used but only when there is some `experience` in\n",
    "    the resume. Talk about the person's `projects` in brief if no `experience` (in bullet points). Mention a few lines about the `certifications` as well.\n",
    "    The mail should be formal and a minimum of 2-3 paragraphs long. The mail should be in first person format like you are the person who is applying \n",
    "    for the job. Also mention that you have attached the resume in the mail for further reference. Make the mail convincing. At the end after the name,\n",
    "    add the linkedin url, and the `mobile no.` of the person from their resume. Add a little space after every paragraph.\n",
    "    ### (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "cold_email_chain = cold_email_prompt | cold_email_llm\n",
    "cold_email_result = cold_email_chain.invoke(input = {'job_details_json': parsed_job_data, 'resume_details_json': resume_json})\n",
    "print(cold_email_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd40518-3497-4e48-8880-8f7b10d68729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
